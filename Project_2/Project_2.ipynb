{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk(\"./\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Frame the problem\n",
    "Using the customer description, Define the problem your trying to solve in your own words (remember this is not technial but must be specific so the customer understands the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape housing Data from San Francisco Area to accurately predict housing prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get the Data \n",
    "Define how you recieved the data (provided, gathered..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/models.py:976\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 976\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m TS \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m OUT \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSF_HomeHarvest_.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m raw \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_property\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSan Francisco, CA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlisting_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msold\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_days\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_property_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetched \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(raw)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows before filtering\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m df \u001b[38;5;241m=\u001b[39m raw\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/homeharvest/__init__.py:66\u001b[0m, in \u001b[0;36mscrape_property\u001b[0;34m(location, listing_type, return_type, property_type, radius, mls_only, past_days, proxy, date_from, date_to, foreclosure, extra_property_data, exclude_pending, limit)\u001b[0m\n\u001b[1;32m     48\u001b[0m scraper_input \u001b[38;5;241m=\u001b[39m ScraperInput(\n\u001b[1;32m     49\u001b[0m     location\u001b[38;5;241m=\u001b[39mlocation,\n\u001b[1;32m     50\u001b[0m     listing_type\u001b[38;5;241m=\u001b[39mListingType(listing_type\u001b[38;5;241m.\u001b[39mupper()),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m     limit\u001b[38;5;241m=\u001b[39mlimit,\n\u001b[1;32m     63\u001b[0m )\n\u001b[1;32m     65\u001b[0m site \u001b[38;5;241m=\u001b[39m RealtorScraper(scraper_input)\n\u001b[0;32m---> 66\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43msite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scraper_input\u001b[38;5;241m.\u001b[39mreturn_type \u001b[38;5;241m!=\u001b[39m ReturnType\u001b[38;5;241m.\u001b[39mpandas:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/homeharvest/core/scrapers/realtor/__init__.py:383\u001b[0m, in \u001b[0;36mRealtorScraper.search\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    369\u001b[0m     futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    370\u001b[0m         executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m    371\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneral_search,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    379\u001b[0m         )\n\u001b[1;32m    380\u001b[0m     ]\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m as_completed(futures):\n\u001b[0;32m--> 383\u001b[0m         homes\u001b[38;5;241m.\u001b[39mextend(\u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    385\u001b[0m \u001b[38;5;66;03m# Apply client-side date filtering for PENDING properties\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;66;03m# (server-side filters are broken in the API)\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlisting_type \u001b[38;5;241m==\u001b[39m ListingType\u001b[38;5;241m.\u001b[39mPENDING \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_x_days \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdate_from):\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/homeharvest/core/scrapers/realtor/__init__.py:261\u001b[0m, in \u001b[0;36mRealtorScraper.general_search\u001b[0;34m(self, variables, search_type)\u001b[0m\n\u001b[1;32m    255\u001b[0m payload \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: query,\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariables\u001b[39m\u001b[38;5;124m\"\u001b[39m: variables,\n\u001b[1;32m    258\u001b[0m }\n\u001b[1;32m    260\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mpost(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSEARCH_GQL_URL, json\u001b[38;5;241m=\u001b[39mpayload)\n\u001b[0;32m--> 261\u001b[0m response_json \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m search_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhome_search\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhome_search\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m query \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproperty_search\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    264\u001b[0m properties: \u001b[38;5;28mlist\u001b[39m[Union[Property, \u001b[38;5;28mdict\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/models.py:980\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[0;32m--> 980\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from homeharvest import scrape_property\n",
    "\n",
    "TS = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "OUT = Path(f\"SF_HomeHarvest_{TS}.csv\")\n",
    "\n",
    "\n",
    "raw = scrape_property(\n",
    "    location=\"San Francisco, CA\",\n",
    "    listing_type=\"sold\",         \n",
    "    past_days=200,\n",
    "    extra_property_data=True\n",
    ")\n",
    "\n",
    "print(f\"Fetched {len(raw):,} rows before filtering\")\n",
    "\n",
    "df = raw.copy()\n",
    "city_cols = [c for c in df.columns if c.lower() in {\"city\"}]\n",
    "if city_cols:\n",
    "    df = df[df[city_cols[0]].str.fullmatch(\"San Francisco\", na=False)]\n",
    "else:\n",
    "    addr_col = next((c for c in df.columns if \"address\" in c.lower() or \"permalink\" in c.lower()), None)\n",
    "    if addr_col:\n",
    "        df = df[df[addr_col].str.contains(\", San Francisco, CA\", na=False)]\n",
    "\n",
    "\n",
    "df = df.drop_duplicates(subset=[c for c in df.columns if \"id\" in c.lower()] or None)\n",
    "df.to_csv(OUT, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Explore the Data\n",
    "Gain insights into the data you have from step 2, making sure to identify any bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2844, 7) (711, 7)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SRC = \"SF_HomeHarvest_20250910_235144.csv\"  \n",
    "df = pd.read_csv(SRC)\n",
    "\n",
    "keep_like = {\n",
    "    \"address\": [c for c in df.columns if \"address\" in c.lower()] or [None],\n",
    "    \"price\":   [c for c in df.columns if \"price\" in c.lower() and \"list\" not in c.lower()],\n",
    "    \"beds\":    [c for c in df.columns if \"bed\" in c.lower()],\n",
    "    \"baths\":   [c for c in df.columns if \"bath\" in c.lower()],\n",
    "    \"area\":    [c for c in df.columns if \"sq\" in c.lower() or \"area\" in c.lower()],\n",
    "    \"type\":    [c for c in df.columns if \"type\" in c.lower() or \"style\" in c.lower()],\n",
    "}\n",
    "addr = keep_like[\"address\"][0]\n",
    "price = keep_like[\"price\"][0]\n",
    "beds = keep_like[\"beds\"][0]\n",
    "baths = keep_like[\"baths\"][0]\n",
    "area = keep_like[\"area\"][0]\n",
    "ptype = keep_like[\"type\"][0]\n",
    "\n",
    "core = df[[addr, price, beds, baths, area, ptype]].rename(columns={\n",
    "    addr: \"Address\",\n",
    "    price: \"SoldPrice\",\n",
    "    beds: \"Bedrooms\",\n",
    "    baths: \"Bathrooms\",\n",
    "    area: \"AreaSqFt\",\n",
    "    ptype: \"PropertyType\",\n",
    "})\n",
    "\n",
    "def sf_neighborhood(addr: str) -> str:\n",
    "    if not isinstance(addr, str):\n",
    "        return \"San Francisco\"\n",
    "    m = re.search(r\",\\s*([^,]+),\\s*San Francisco,\\s*CA\", addr)\n",
    "    return m.group(1).strip() if m else \"San Francisco\"\n",
    "\n",
    "core[\"Neighborhood\"] = core[\"Address\"].apply(sf_neighborhood)\n",
    "\n",
    "core.to_csv(\"sf_core.csv\", index=False)\n",
    "train, test = train_test_split(core, test_size=0.2, random_state=1337)\n",
    "train.to_csv(\"sf_train.csv\", index=False)\n",
    "test.to_csv(\"sf_test.csv\", index=False)\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Prepare the Data\n",
    "\n",
    "\n",
    "Apply any data transformations and explain what and why\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picked columns: {'addr': 'Address', 'price': 'SoldPrice', 'beds': 'Bedrooms', 'baths': 'Bathrooms', 'area': 'AreaSqFt', 'ptype': 'PropertyType'}\n",
      "Clean rows: 3554 | Train: 2843 | Test: 711\n"
     ]
    }
   ],
   "source": [
    "import re, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "candidates = sorted(glob.glob(\"SF_HomeHarvest_20250910_235144.csv\") + glob.glob(\"sf_core.csv\"))\n",
    "SRC = candidates[-1]\n",
    "df = pd.read_csv(SRC)\n",
    "\n",
    "def pick(*keys):\n",
    "    keys = [k.lower() for k in keys]\n",
    "    # exact-ish preference pass\n",
    "    for c in df.columns:\n",
    "        lc = c.lower()\n",
    "        if any(k == lc for k in keys):\n",
    "            return c\n",
    "    # substring fallback pass\n",
    "    for c in df.columns:\n",
    "        lc = c.lower()\n",
    "        if any(k in lc for k in keys):\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "addr  = pick(\"address\", \"full_address\", \"permalink\", \"property_url\")\n",
    "price = pick(\"sold price\", \"closing price\", \"sold_price\", \"price\")\n",
    "beds  = pick(\"bedrooms\", \"beds\", \"bed\")\n",
    "baths = pick(\"bathrooms\", \"baths\", \"bath\")\n",
    "area  = pick(\"area (sqft)\", \"sqft\", \"area\", \"living area\")\n",
    "ptype = pick(\"property type\", \"style\", \"type\")\n",
    "\n",
    "found = {\"addr\":addr,\"price\":price,\"beds\":beds,\"baths\":baths,\"area\":area,\"ptype\":ptype}\n",
    "print(\"Picked columns:\", found)\n",
    "\n",
    "if any(v is None for v in found.values()):\n",
    "    missing = [k for k, v in found.items() if v is None]\n",
    "    raise ValueError(f\"Could not find required columns for: {missing}. \"\n",
    "                     f\"Available cols: {list(df.columns)}\")\n",
    "\n",
    "core = df[[addr, price, beds, baths, area, ptype]].rename(columns={\n",
    "    addr:\"Address\", price:\"SoldPrice\", beds:\"Bedrooms\",\n",
    "    baths:\"Bathrooms\", area:\"AreaSqFt\", ptype:\"PropertyType\"\n",
    "})\n",
    "\n",
    "core = core[core[\"Address\"].astype(str).str.contains(r\",\\s*San Francisco,\\s*CA\", na=False)]\n",
    "if core.empty:\n",
    "    raise ValueError(\"SF filter removed all rows. Check that addresses contain ', San Francisco, CA'.\")\n",
    "\n",
    "core[\"Neighborhood\"] = core[\"Address\"].str.extract(r\",\\s*([^,]+),\\s*San Francisco,\\s*CA\")\n",
    "core[\"Neighborhood\"] = core[\"Neighborhood\"].fillna(\"San Francisco\")\n",
    "\n",
    "for col in [\"SoldPrice\",\"Bedrooms\",\"Bathrooms\",\"AreaSqFt\"]:\n",
    "    core[col] = pd.to_numeric(core[col], errors=\"coerce\")\n",
    "    core[col] = core[col].fillna(core[col].median())\n",
    "\n",
    "if core[\"PropertyType\"].isna().all():\n",
    "    core[\"PropertyType\"] = \"Unknown\"\n",
    "else:\n",
    "    core[\"PropertyType\"] = core[\"PropertyType\"].fillna(core[\"PropertyType\"].mode(dropna=True).iloc[0])\n",
    "\n",
    "core[\"PricePerSqFt\"] = np.where(core[\"AreaSqFt\"] > 0,\n",
    "                                core[\"SoldPrice\"] / core[\"AreaSqFt\"],\n",
    "                                core[\"SoldPrice\"])\n",
    "\n",
    "final_cols = [\"Bedrooms\",\"Bathrooms\",\"AreaSqFt\",\"PricePerSqFt\",\n",
    "              \"PropertyType\",\"Neighborhood\",\"SoldPrice\",\"Address\"]\n",
    "core = core[final_cols].drop_duplicates().reset_index(drop=True)\n",
    "core.to_csv(\"sf_clean.csv\", index=False)\n",
    "\n",
    "train, test = train_test_split(core, test_size=0.2, random_state=1337)\n",
    "train.to_csv(\"sf_train.csv\", index=False)\n",
    "test.to_csv(\"sf_test.csv\", index=False)\n",
    "\n",
    "print(f\"Clean rows: {len(core)} | Train: {len(train)} | Test: {len(test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model the data\n",
    "Using selected ML models, experment with your choices and describe your findings. Finish by selecting a Model to continue with\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HGBR: MAE=$755,728  R²=0.171\n",
      "RF: MAE=$693,936  R²=0.318\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor\n",
    "\n",
    "df = pd.read_csv(\"sf_core.csv\").dropna(subset=[\"SoldPrice\"])\n",
    "y = df[\"SoldPrice\"].astype(float)\n",
    "X = df.drop(columns=[\"SoldPrice\", \"Address\"])\n",
    "\n",
    "num_cols = [\"Bedrooms\", \"Bathrooms\", \"AreaSqFt\"]\n",
    "cat_cols = [\"PropertyType\", \"Neighborhood\"]\n",
    "\n",
    "pre = ColumnTransformer(\n",
    "    [\n",
    "        (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "                          (\"sc\", StandardScaler())]), num_cols),\n",
    "        (\"cat\", Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                          (\"oh\", OneHotEncoder(handle_unknown=\"ignore\"))]), cat_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"HGBR\": HistGradientBoostingRegressor(max_depth=6, learning_rate=0.08, max_iter=600, random_state=1337),\n",
    "    \"RF\":   RandomForestRegressor(n_estimators=350, max_depth=8, min_samples_leaf=4, random_state=1337, n_jobs=-1),\n",
    "}\n",
    "\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, random_state=1337)\n",
    "\n",
    "for name, est in models.items():\n",
    "    pipe = Pipeline([(\"pre\", pre), (\"est\", est)])\n",
    "    pipe.fit(Xtr, ytr)\n",
    "    pred = pipe.predict(Xte)\n",
    "    mae = mean_absolute_error(yte, pred)\n",
    "    r2  = r2_score(yte, pred)\n",
    "    print(f\"{name}: MAE=${mae:,.0f}  R²={r2:0.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Fine Tune the Model\n",
    "\n",
    "With the select model descibe the steps taken to acheve the best rusults possiable \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Present\n",
    "In a customer faceing Document provide summery of finding and detail approach taken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Launch the Model System\n",
    "Define your production run code, This should be self susficent and require only your model pramaters \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infrence(prams):\n",
    "    results = m.run(prams)\n",
    "    return results "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
